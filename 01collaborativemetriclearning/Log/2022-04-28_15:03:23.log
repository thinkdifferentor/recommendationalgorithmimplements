Recall on (sampled) validation set: 0.0001
Training loss 55507.68359375
Recall on (sampled) validation set: 0.03907906481710056
Training loss 60200.66796875
Recall on (sampled) validation set: 0.07942064952547079
Training loss 51503.953125
Recall on (sampled) validation set: 0.10726063971639273
Training loss 51822.7578125
Recall on (sampled) validation set: 0.13451754595051674
Training loss 48634.7734375
Recall on (sampled) validation set: 0.14229103224508202
Training loss 45910.421875
Recall on (sampled) validation set: 0.1563479363372193
Training loss 48644.0078125
Recall on (sampled) validation set: 0.16877761313190434
Training loss 42563.61328125
Recall on (sampled) validation set: 0.1833686418153007
Training loss 46976.171875
Recall on (sampled) validation set: 0.20650769595795604
Training loss 42631.21484375
Recall on (sampled) validation set: 0.19162165504434722
Training loss 44707.41015625
Recall on (sampled) validation set: 0.20337611543634246
Training loss 44265.33984375
Recall on (sampled) validation set: 0.1958543114780779
Training loss 42939.33203125
Recall on (sampled) validation set: 0.19967574403741492
Training loss 45967.453125
Recall on (sampled) validation set: 0.2153427867511379
Training loss 41038.96484375
Recall on (sampled) validation set: 0.21007315390081766
Training loss 45257.30859375
Recall on (sampled) validation set: 0.2071798842627784
Training loss 41902.15234375
Recall on (sampled) validation set: 0.20308153900033346
Training loss 43599.80859375
Recall on (sampled) validation set: 0.20887556796837037
Training loss 43346.51953125
Recall on (sampled) validation set: 0.2091397807011536
Training loss 42410.1328125
Recall on (sampled) validation set: 0.21743753966780024
Training loss 45233.6328125
Recall on (sampled) validation set: 0.21863648775455455
Training loss 40931.7109375
Recall on (sampled) validation set: 0.21936923751881773
Training loss 44657.4375
Recall on (sampled) validation set: 0.21315559153308677
Training loss 41527.3125
Recall on (sampled) validation set: 0.21428320673292223
Training loss 43476.8515625
Recall on (sampled) validation set: 0.21669858372911063
Training loss 43415.5546875
Recall on (sampled) validation set: 0.2046694190860647
Training loss 42171.51171875
Recall on (sampled) validation set: 0.20899496330509135
Training loss 44725.6640625
Recall on (sampled) validation set: 0.22237441581523576
Training loss 40717.98046875
Recall on (sampled) validation set: 0.20310214415505798
Training loss 44333.1875
Recall on (sampled) validation set: 0.21781093638286428
Training loss 41640.82421875
Recall on (sampled) validation set: 0.2112091951306692
Training loss 43066.12109375
Recall on (sampled) validation set: 0.21794222873828187
Training loss 43803.91796875
Recall on (sampled) validation set: 0.21336857028772277
Training loss 41847.125
Recall on (sampled) validation set: 0.21761139316046085
Training loss 44302.7109375
Recall on (sampled) validation set: 0.21480183998322142
Training loss 40707.9375
Recall on (sampled) validation set: 0.21450700866743477
Training loss 43892.5625
Recall on (sampled) validation set: 0.21456816448106855
Training loss 41736.3984375
Recall on (sampled) validation set: 0.21007910308134076
Training loss 42810.359375
Recall on (sampled) validation set: 0.2104812996262811
Training loss 43017.57421875
Recall on (sampled) validation set: 0.2145757968610575
Training loss 41952.11328125
Recall on (sampled) validation set: 0.21349061875282127
Training loss 44305.5703125
Recall on (sampled) validation set: 0.22385768462977224
Training loss 40637.328125
Recall on (sampled) validation set: 0.21268704393885424
Training loss 43970.69921875
Recall on (sampled) validation set: 0.21744181669998572
Training loss 42320.69921875
Recall on (sampled) validation set: 0.22177750980507677
Training loss 42839.55859375
Recall on (sampled) validation set: 0.2206344839074618
Training loss 43416.6875
Recall on (sampled) validation set: 0.21787696675799742
Training loss 41741.6875
Recall on (sampled) validation set: 0.22209626086268153
Training loss 44731.1328125
Recall on (sampled) validation set: 0.22242766588756072
Training loss 40662.70703125
Recall on (sampled) validation set: 0.21927993169326476
The best recall is 0.22385768462977224
